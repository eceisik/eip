{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2460283-f87c-4ab5-8195-b3e092c67e67",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "488bebb5-dcec-4a94-9ea1-8ab87396037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d690ca86-69ae-444b-a767-4ffd09593a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normality(data):\n",
    "    test_stat_normality, p_value_normality=stats.shapiro(data)\n",
    "    print(\"p value:%.4f\" % p_value_normality)\n",
    "    if p_value_normality <0.05:\n",
    "        print(\"Reject null hypothesis >> The data is not normally distributed\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The data is normally distributed\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218530c7-e10e-459e-b51e-99306814301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variance_homogeneity(group1, group2):\n",
    "    test_stat_var, p_value_var= stats.levene(group1,group2)\n",
    "    print(\"p value:%.4f\" % p_value_var)\n",
    "    if p_value_var <0.05:\n",
    "        print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721ee575-b70e-4d81-9bdf-f1b59f449784",
   "metadata": {},
   "source": [
    "## Q1.   \n",
    " A university professor gave online lectures instead of face-to-face classes due to Covid-19. Later, he uploaded recorded lectures to the cloud for students who followed the course asynchronously (those who did not attend the lesson but later watched the records). However, he believes that the students who attend class at the class time and participate in the process are more successful. Therefore, he recorded the average grades of the students at the end of the semester. The data is below. \n",
    "\n",
    "synchronous = [94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6]      \n",
    "asynchronous = [77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2]\n",
    "\n",
    "**Conduct the hypothesis testing to check whether the professor's belief is statistically significant by using a 0.05 significance level to evaluate the null and alternative hypotheses. Before doing hypothesis testing, check the related assumptions. Comment on the results.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d27ff3-fd89-435a-b753-7388831b18e3",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "Observations in each sample are independent and identically distributed (iid).  \n",
    "Observations in each sample are normally distributed.  \n",
    "Observations in each sample have the same variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a25db91-cefa-4a38-9946-d0e87323e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync = np.array([94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2,\n",
    "       87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6])\n",
    "asyncr =np.array([77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3a54f-c5ad-4c93-b7ff-53501ae6ae11",
   "metadata": {},
   "source": [
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed.   \n",
    "Assume that alpha=0.05 If p-value is >0.05, it can be said that data is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e1a394-4670-43e8-945e-dd7158652548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.6556\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0803\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(sync)\n",
    "check_normality(asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e945b-dd2d-405b-99c1-80e29378ced7",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are same.  \n",
    "$H_{1}$: The variances of the samples are different.\n",
    "    \n",
    "It tests the null hypothesis that the population variances are equal (called homogeneity of variance or homoscedasticity). If the resulting p-value of Levene's test is less than some significance level (typically 0.05), the obtained differences in sample variances are unlikely to have occurred based on random sampling from a population with equal variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551145dd-a579-4d1b-8829-47b63be40606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.8149\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "check_variance_homogeneity(sync, asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110fd891-051e-438c-aafb-d7d97c7ebb42",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{s}<= \\mu_{a}$     \n",
    "$H_{1}$: $\\mu_{s}>  \\mu_{a}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e08cc74-4d59-4782-957e-d7c9d7ebf972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.00753598\n",
      "since the hypothesis is one sided >> use p_value/2 >> p_value_one_sided:0.0038\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest,p_value = stats.ttest_ind(sync,asyncr)\n",
    "print(\"p value:%.8f\" % p_value)\n",
    "print(\"since the hypothesis is one sided >> use p_value/2 >> p_value_one_sided:%.4f\" %(p_value/2))\n",
    "if p_value/2 <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120ebc6-5dbf-4324-8a8d-b59da42b492f",
   "metadata": {},
   "source": [
    "**At this significance level, there is enough evidence to conclude that the average grade of the students who follow the course synchronously is higher than the async.** \n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920da3c-a070-493e-a55c-9ff7c91d63d1",
   "metadata": {},
   "source": [
    "## Q2.\n",
    "A pediatrician wants to see the effect of formula consumption on the average monthly weight gain (in gr) of babies. For this reason, she collected  data from three different groups. The first group is exclusively breastfed children(receives only breast milk), the second group is children who are fed with only formula and the last group is both formula and breastfed children. These data are as below \n",
    "\n",
    "\n",
    "only_breast=[794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7,\n",
    "       717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1]      \n",
    "   \n",
    "only_formula=[ 898.8,  881.2,  940.2,  966.2,  957.5, 1061.7, 1046.2,  980.4,\n",
    "        895.6,  919.7, 1074.1,  952.5,  796.3,  859.6,  871.1 , 1047.5,\n",
    "        919.1 , 1160.5,  996.9]     \n",
    "        \n",
    "both=[976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6,\n",
    "       805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 ,\n",
    "       823.6, 818.7, 926.8, 791.7, 948.3]  \n",
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the average monthly gain of these three groups by using a 0.05 significance level. If there is a significant difference, perform further analysis to find what caused the difference.  Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abcb71a-0743-4d59-8ee9-8d8d25a8cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_breast=np.array([794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7,\n",
    "       717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1])\n",
    "\n",
    "only_formula=np.array([ 898.8,  881.2,  940.2,  966.2,  957.5, 1061.7, 1046.2,  980.4,\n",
    "        895.6,  919.7, 1074.1,  952.5,  796.3,  859.6,  871.1 , 1047.5,\n",
    "        919.1 , 1160.5,  996.9])\n",
    "\n",
    "both=np.array([976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6,\n",
    "       805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 ,\n",
    "       823.6, 818.7, 926.8, 791.7, 948.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d0b45-345f-476d-be7a-5f0d726b86e6",
   "metadata": {},
   "source": [
    "$ H_{0} $: The data is normally distributed.  \n",
    "$ H_{1} $: The data is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a50ef3-592f-4004-9cf6-6fa6ccd86ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.4694\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.8879\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.7973\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(only_breast)\n",
    "check_normality(only_formula)\n",
    "check_normality(both)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1035d5-40fd-4dc2-bb1a-0ee0aeea6123",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are the same.  \n",
    "$H_{1}$: The variances of the samples are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb110b24-f346-4429-a694-901455404823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.7673\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(only_breast,only_formula,both)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52832a4a-3f1a-4834-8cb9-0b3cca65cb74",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{1}= \\mu_{2}= \\mu_{3} $ **or** The mean of the samples is the same.      \n",
    "$H_{1}$: At least one of them is different.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44853735-4d94-42b8-b5d9-932915ea2f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000000\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.f_oneway(only_breast,only_formula,both)\n",
    "print(\"p value:%.6f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8802c38-988d-483f-b2cf-3434ae71f1cf",
   "metadata": {},
   "source": [
    "**At this significance level, it can be concluded that at least one of the groups has a different average monthly weight gain.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ab76a-6dd1-46a9-aebe-7871b4280766",
   "metadata": {},
   "source": [
    "### post hoc // pairwise comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b17cf58-588b-40dd-9704-3856a60673fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_41116_row0_col0,#T_41116_row0_col2,#T_41116_row1_col1,#T_41116_row2_col0,#T_41116_row2_col2{\n",
       "            background-color:  white;\n",
       "        }#T_41116_row0_col1,#T_41116_row1_col0,#T_41116_row1_col2,#T_41116_row2_col1{\n",
       "            background-color: violet;\n",
       "        }</style><table id=\"T_41116_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >only breast</th>        <th class=\"col_heading level0 col1\" >only formula</th>        <th class=\"col_heading level0 col2\" >both</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_41116_level0_row0\" class=\"row_heading level0 row0\" >only breast</th>\n",
       "                        <td id=\"T_41116_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_41116_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "                        <td id=\"T_41116_row0_col2\" class=\"data row0 col2\" >0.129454</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_41116_level0_row1\" class=\"row_heading level0 row1\" >only formula</th>\n",
       "                        <td id=\"T_41116_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "                        <td id=\"T_41116_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_41116_row1_col2\" class=\"data row1 col2\" >0.000004</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_41116_level0_row2\" class=\"row_heading level0 row2\" >both</th>\n",
       "                        <td id=\"T_41116_row2_col0\" class=\"data row2 col0\" >0.129454</td>\n",
       "                        <td id=\"T_41116_row2_col1\" class=\"data row2 col1\" >0.000004</td>\n",
       "                        <td id=\"T_41116_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2aa0c2c2308>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install scikit-posthocs\n",
    "# Pairwise T test for multiple comparisons of independent groups. May be used after a parametric ANOVA to do pairwise comparisons.\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "posthoc_df= sp.posthoc_ttest([only_breast,only_formula,both], equal_var=True, p_adjust=\"bonferroni\")\n",
    "\n",
    "group_names= [\"only breast\", \"only formula\",\"both\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8845fa14-62fe-4948-a317-b8054e53fe32",
   "metadata": {},
   "source": [
    "**At this significance level, it can be concluded that**\n",
    "- \"only breast\" is different than \"only formula\"\n",
    "- \"only formula\" is different than both \"only breast\" and \"both\"\n",
    "- \"both\" is different than \"only formula\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fce1617-3e9a-4c98-84b8-8f7e7327be11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1      2      3\n",
       "1 1.0000 0.0000 0.0432\n",
       "2 0.0000 1.0000 0.0000\n",
       "3 0.0432 0.0000 1.0000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.posthoc_ttest([only_breast,only_formula,both], equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9823d16-7c42-445f-9f2f-c240af34ae70",
   "metadata": {},
   "source": [
    "-------\n",
    "## Q3.\n",
    "A human resource specialist working in a technology company is interested in the overwork time of different teams. To investigate whether there is a difference between overtime of the software development team and the test team, she selected 17 employees randomly in each of the two teams and recorded their weekly average overwork time in terms of an hour. The data is below.   \n",
    "\n",
    "test_team=[6.2,  7.1,  1.5,  2,3 ,  2,  1.5,  6.1,  2.4,  2.3, 12.4,  1.8,  5.3,  3.1, 9.4,  2.3, 4.1]    \n",
    "software_team=[2.3,  2.1,  1.4,  2.0, 8.7,  2.2,  3.1,  4.2,  3.6, 2.5,  3.1,  6.2, 12.1,  3.9,  2.2, 1.2 ,3.4]\n",
    "\n",
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the overwork time of two teams by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd896ab-39b8-4fa2-a188-86e7706d54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team=np.array([6.2,  7.1,  1.5,  2,3 ,  2,  1.5,  6.1,  2.4,  2.3, 12.4,  1.8,  5.3,  3.1, 9.4,  2.3, 4.1])\n",
    "developer_team=np.array([2.3,  2.1,  1.4,  2.0, 8.7,  2.2,  3.1,  4.2,  3.6, 2.5,  3.1,  6.2, 12.1,  3.9,  2.2, 1.2 ,3.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69375bca-0f3a-4a37-bf8b-c099521b96ee",
   "metadata": {},
   "source": [
    "$ H_{0} $: The data is normally distributed.  \n",
    "$ H_{1} $: The data is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dcbc510-36a3-4b28-98fd-6c67be18a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0046\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.0005\n",
      "Reject null hypothesis >> The data is not normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_team)\n",
    "check_normality(developer_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e832e78-9c7f-48b7-9b31-6850bb07a22b",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are the same.  \n",
    "$H_{1}$: The variances of the samples are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b59c9a14-1416-4e0e-a508-9e39fe5a073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.5410\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "check_variance_homogeneity(test_team, developer_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a1342a-22d8-4e3a-ad2a-6616509a588d",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{1}= \\mu_{2}$  **or** $\\mu_{1}- \\mu_{2} = 0 $  **or** The mean of the samples are same.      \n",
    "$H_{1}$: $\\mu_{1} \\neq \\mu_{2}$  **or** $\\mu_{1}- \\mu_{2} \\neq 0 $  **or** The mean of the samples are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88f9d15e-cd09-4dce-abce-58b42c13ef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:0.8226\n",
      "Fail to recejt null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest,pvalue = stats.mannwhitneyu(test_team,developer_team, alternative=\"two-sided\")\n",
    "print(\"p-value:%.4f\" % pvalue)\n",
    "if pvalue <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to recejt null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66d3bb-5939-4d6d-ac4c-d8556c22b4b7",
   "metadata": {},
   "source": [
    "At this significance level, it can be said that there is no statistically significant difference between the average overwork time of the two teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2a73c-802d-4f07-8bc3-2c3b3ec7496b",
   "metadata": {},
   "source": [
    "--------\n",
    "## Q4.\n",
    "\n",
    "An e-commerce company regularly advertises on YouTube, Instagram, and Facebook for its campaigns. However, the new manager was curious about if there was any difference between the number of customers attracted by these platforms. Therefore, she started to use Adjust, an application that allows you to find out where your users come from. The daily numbers reported from Adjust for each platform are as below. \n",
    "\n",
    "youtube=[1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956, 2146, 2151, 1943, 2125]\n",
    "       \n",
    "instagram = [2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340., 2349., 2241., 2396., 2244., 2267., 2281.]     \n",
    "       \n",
    "facebook = [2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178., 2113., 2048., 2443., 2265., 2095., 2528.]          \n",
    "\n",
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the average customer acquisition of these three platforms using a 0.05 significance level. If there is a significant difference, perform further analysis to find that caused the difference. Before doing hypothesis testing, check the related assumptions. Comment on the results.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eb4f391-d978-41d9-b8ee-b362cbc403fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube=np.array([1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956,\n",
    "       2146, 2151, 1943, 2125])\n",
    "       \n",
    "instagram =  np.array([2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340.,\n",
    "       2349., 2241., 2396., 2244., 2267., 2281.])\n",
    "       \n",
    "facebook = np.array([2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178.,\n",
    "       2113., 2048., 2443., 2265., 2095., 2528.]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb44a4f-8607-4db7-9c0b-de5ac2182eef",
   "metadata": {},
   "source": [
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23514f87-35bb-40a6-9c26-8572922eac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0285\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.4156\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.1716\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(youtube)\n",
    "check_normality(instagram)\n",
    "check_normality(facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba7cf8-f0e6-47d0-8fe5-6d73881d6d94",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are the same.  \n",
    "$H_{1}$: The variances of the samples are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a96cdc17-bee6-4b26-9ed8-0af5b1123040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0012\n",
      "Reject null hypothesis >> The variances of the samples are different.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(youtube, instagram, facebook)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533008a-5ff3-415a-a479-4c3140407148",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{1}= \\mu_{2}= \\mu_{3} $ **or** The mean of the samples are same.      \n",
    "$H_{1}$: At least one of them is different.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edced263-e6a0-4830-b449-26e3885fd1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000015\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.kruskal(youtube, instagram, facebook)\n",
    "print(\"p value:%.6f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8569ea-87e4-4a9c-8a69-db88a3f3353c",
   "metadata": {},
   "source": [
    "At this significance level, at least one of the average customer acquisition number is different.   \n",
    "Note: Since, the data is not normal, nonparametric version of posthoc test is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2caaea2-1955-4e82-9e61-c2add48aa3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_330a0_row0_col0,#T_330a0_row1_col1,#T_330a0_row1_col2,#T_330a0_row2_col1,#T_330a0_row2_col2{\n",
       "            background-color:  white;\n",
       "        }#T_330a0_row0_col1,#T_330a0_row0_col2,#T_330a0_row1_col0,#T_330a0_row2_col0{\n",
       "            background-color: violet;\n",
       "        }</style><table id=\"T_330a0_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >youtube</th>        <th class=\"col_heading level0 col1\" >instagram</th>        <th class=\"col_heading level0 col2\" >facebook</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_330a0_level0_row0\" class=\"row_heading level0 row0\" >youtube</th>\n",
       "                        <td id=\"T_330a0_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_330a0_row0_col1\" class=\"data row0 col1\" >0.000010</td>\n",
       "                        <td id=\"T_330a0_row0_col2\" class=\"data row0 col2\" >0.002337</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_330a0_level0_row1\" class=\"row_heading level0 row1\" >instagram</th>\n",
       "                        <td id=\"T_330a0_row1_col0\" class=\"data row1 col0\" >0.000010</td>\n",
       "                        <td id=\"T_330a0_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_330a0_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_330a0_level0_row2\" class=\"row_heading level0 row2\" >facebook</th>\n",
       "                        <td id=\"T_330a0_row2_col0\" class=\"data row2 col0\" >0.002337</td>\n",
       "                        <td id=\"T_330a0_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "                        <td id=\"T_330a0_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2aa0c589288>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posthoc_df = sp.posthoc_mannwhitney([youtube,instagram, facebook], p_adjust = 'bonferroni')\n",
    "group_names= [\"youtube\", \"instagram\",\"facebook\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a06307a-6c7f-49e5-95b2-ea66446a569e",
   "metadata": {},
   "source": [
    "The average number of customers coming from YouTube is different than the other (actually smaller than the others).\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5717a45-88fd-49a1-a1b2-22b27b649e04",
   "metadata": {},
   "source": [
    "## Q5.\n",
    "\n",
    "The METU Health Center diagnosed eighteen students with high cholesterol in the previous semester. Healthcare personnel told these patients about the dangers of high cholesterol and prescribed a diet program. One month later, the patients came for control, and their cholesterol level was reexamined. Test whether there is a difference in the cholesterol levels of the patients.   \n",
    "\n",
    "**According to this information, conduct the hypothesis testing to check whether there is a decrease in the cholesterol levels of the patients after the diet by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results**\n",
    "\n",
    "test_results_before_diet=[224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227]  \n",
    "test_results_after_diet=[198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7891668-01fa-44e9-9771-0ea54b4cbba7",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "• The dependent variable must be continuous (interval/ratio)  \n",
    "• The observations are independent of one another  \n",
    "• The dependent variable should be approximately normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bfed26f-592c-490a-9f00-a9c630c1fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_before_diet=np.array([224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227])\n",
    "test_results_after_diet=np.array([198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695778d-95fa-4779-b3b4-c2f089da746f",
   "metadata": {},
   "source": [
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31095b4c-da1f-4149-a518-2efc99edf292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.1635\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.1003\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_results_before_diet)\n",
    "check_normality(test_results_after_diet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696d2f7-613b-4405-850c-09135768e222",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{d}>= 0 $ **or** The true mean difference is equal to or bigger than zero.   \n",
    "$H_{1}$: $\\mu_{d}< 0 $ **or**  The true mean difference is smaller than zero.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70c0d3e5-ac8b-4941-a697-10d830b4acb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000008 one tailed p value:0.000004\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test_stat, p_value_paired = stats.ttest_rel(test_results_before_diet,test_results_after_diet)\n",
    "print(\"p value:%.6f\" % p_value_paired , \"one tailed p value:%.6f\" %(p_value_paired/2))\n",
    "if p_value_paired <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982bb0a-68c7-4b3b-91df-d63e65fba819",
   "metadata": {},
   "source": [
    "At this significance level, there is enough evidence to conclude mean cholesterol level of patients has decreased after the diet.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca16f7-d71f-48ce-ade7-b0c83f03c6b4",
   "metadata": {},
   "source": [
    "## Q6.\n",
    "A venture capitalist wanted to invest in a startup that provides data compression without any loss in quality, but there are two competitors: PiedPiper and EndFrame. Initially, she believed the performance of the EndFrame could be better but still wanted to test it before the investment. Then, she gave the same files to each company to compress and recorded their performance scores. The data is below.    \n",
    "    \n",
    "piedpiper=[4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25]     \n",
    "endframe = [4.27, 3.93, 4.01, 4.07, 3.87, 4.  , 4.  , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09]\n",
    "\n",
    "\n",
    "**According to this information, conduct the related hypothesis testing by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf02bf9d-124b-48f8-aa7c-07c4e3176274",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "• The dependent variable must be continuous (interval/ratio)  \n",
    "• The observations are independent of one another  \n",
    "• The dependent variable should be approximately normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925fc7a-d032-4b41-975d-8ddecfb2b08e",
   "metadata": {},
   "source": [
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed.   \n",
    "Assume that alpha=0.05 If p-value is >0.05, it can be said that data is normality distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "340b370e-4e26-43c7-83f9-0d9d2291dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0304\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.9587\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "piedpiper=np.array([4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25])\n",
    "endframe = np.array([4.27, 3.93, 4.01, 4.07, 3.87, 4.  , 4.  , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09])\n",
    "check_normality(piedpiper)\n",
    "check_normality(endframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7dfe1-e1b3-4ccf-9a1a-2d31db50bcfa",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{d} >= 0 $ **or** The true mean difference is equal to or bigger than zero.   \n",
    "$H_{1}$: $\\mu_{d} < 0 $ **or**  The true mean difference is smaller than zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a50efce1-4f5e-4c54-a92c-814d3069d8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:0.000214 >> one_tailed_pval:0.000107\n",
      "one sided pvalue:0.000107\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test,pvalue = stats.wilcoxon(endframe,piedpiper) ##alternative default two sided\n",
    "print(\"p-value:%.6f\" %pvalue, \">> one_tailed_pval:%.6f\" %(pvalue/2))\n",
    "\n",
    "test,one_sided_pvalue = stats.wilcoxon(endframe,piedpiper, alternative=\"less\")\n",
    "print(\"one sided pvalue:%.6f\" %(one_sided_pvalue))\n",
    "if pvalue <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to recejt null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc8244-e8fe-4823-93b8-ee5f252cb62d",
   "metadata": {},
   "source": [
    "Reject $H_{0}$ >> At this significance level, there is enough evidence to conclude that the performance the PiedPaper is better than the EndFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe54ac-4521-49c1-8d8f-daa746a7371a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Q7.\n",
    "\n",
    "A researcher was curious about whether there is a difference between the methodology she developed, C, and baseline methods A and B in terms of performance. Therefore, she decided to design different experiments and recorded the achieved accuracy by each method. The below table shows the achieved accuracy on test sets by each method. Please note that the same train and test sets were used for each method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20131b7-2d5b-44d3-b521-9caa88ec5174",
   "metadata": {},
   "source": [
    "| Experiment |   A  |   B  |   C  |\n",
    "|:----------:|:----:|:----:|:----:|\n",
    "|     E1     | 89.8 | 90.0 | 91.5 |\n",
    "|     E2     | 89.9 | 90.1 | 90.7 |\n",
    "|     E3     | 88.6 | 88.8 | 90.3 |\n",
    "|     E4     | 88.7 | 88.9 | 90.4 |\n",
    "|     E5     | 89.6 | 89.9 | 90.2 |\n",
    "|     E6     | 89.7 | 90.0 | 90.3 |\n",
    "|     E7     | 89.2 | 89.0 | 90.2 |\n",
    "|     E8     | 89.3 | 89.2 | 90.3 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff2e99-7eaa-4b4c-8728-2956154dbf71",
   "metadata": {},
   "source": [
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the performance of the methods by using a 0.05 significance level. If there is a significant difference, perform further analysis to find which one caused the difference. Before doing hypothesis testing, check the related assumptions. Comment on the results.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c19e2-8d30-4ec3-9760-41e49a370454",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "Observations in each sample are independent and identically distributed (iid).  \n",
    "Observations in each sample are normally distributed.  \n",
    "Observations in each sample have the same variance. \n",
    "    \n",
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d73081be-eb32-4b2d-b456-a153e756ed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.3076\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0515\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0016\n",
      "Reject null hypothesis >> The data is not normally distributed\n"
     ]
    }
   ],
   "source": [
    "method_A = np.array([89.8, 89.9, 88.6, 88.7, 89.6, 89.7, 89.2, 89.3])\n",
    "method_B =   np.array([90.0, 90.1, 88.8, 88.9, 89.9, 90.0, 89.0, 89.2])\n",
    "method_C = np.array([91.5, 90.7, 90.3, 90.4, 90.2, 90.3, 90.2, 90.3])\n",
    "\n",
    "check_normality(method_A)\n",
    "check_normality(method_B)\n",
    "check_normality(method_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c9661-5158-4931-bc06-3cc9101910a7",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are the same.  \n",
    "$H_{1}$: The variances of the samples are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2ddd1ce-2b5d-4fc1-a27d-b6f571c070d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.1953\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(method_A, method_B, method_C)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37d5e449-2f6c-4268-adb1-2ef51d6a3f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0015\n",
      "Reject null hypothesis\n",
      "89.35 89.49 90.49\n"
     ]
    }
   ],
   "source": [
    "test_stat,p_value = stats.friedmanchisquare(method_A,method_B, method_C)\n",
    "print(\"p value:%.4f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")\n",
    "    \n",
    "print(np.round(np.mean(method_A),2), np.round(np.mean(method_B),2), np.round(np.mean(method_C),2))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27e112-4aa2-4273-9af5-d5cdde8389f5",
   "metadata": {},
   "source": [
    "### posthoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "548efff2-1410-4bed-a5e9-68feb995dc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_31372_row0_col0,#T_31372_row0_col1,#T_31372_row1_col0,#T_31372_row1_col1,#T_31372_row2_col2{\n",
       "            background-color:  white;\n",
       "        }#T_31372_row0_col2,#T_31372_row1_col2,#T_31372_row2_col0,#T_31372_row2_col1{\n",
       "            background-color: violet;\n",
       "        }</style><table id=\"T_31372_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Method A</th>        <th class=\"col_heading level0 col1\" >Method B</th>        <th class=\"col_heading level0 col2\" >Method C</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_31372_level0_row0\" class=\"row_heading level0 row0\" >Method A</th>\n",
       "                        <td id=\"T_31372_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_31372_row0_col1\" class=\"data row0 col1\" >0.078125</td>\n",
       "                        <td id=\"T_31372_row0_col2\" class=\"data row0 col2\" >0.023438</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_31372_level0_row1\" class=\"row_heading level0 row1\" >Method B</th>\n",
       "                        <td id=\"T_31372_row1_col0\" class=\"data row1 col0\" >0.078125</td>\n",
       "                        <td id=\"T_31372_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_31372_row1_col2\" class=\"data row1 col2\" >0.023438</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_31372_level0_row2\" class=\"row_heading level0 row2\" >Method C</th>\n",
       "                        <td id=\"T_31372_row2_col0\" class=\"data row2 col0\" >0.023438</td>\n",
       "                        <td id=\"T_31372_row2_col1\" class=\"data row2 col1\" >0.023438</td>\n",
       "                        <td id=\"T_31372_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2aa0c6e1f08>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([method_A, method_B, method_C]) \n",
    "posthoc_df=sp.posthoc_wilcoxon(data, p_adjust=\"holm\")\n",
    "# posthoc_df = sp.posthoc_nemenyi_friedman(data.T) ## another option for the posthoc test\n",
    "\n",
    "group_names= [\"Method A\", \"Method B\",\"Method C\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cfdac-be25-4bfc-b07d-8ef905c99f36",
   "metadata": {},
   "source": [
    "Method C outperformed others and achieved better accuracy scores than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b478f-20d5-475f-a050-934c293c5cca",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## Q8.\n",
    "\n",
    "An analyst of a financial investment company is curious about the relationship between gender and risk appetite. A random sample was taken of 660 customers from the database. The customers in the sample were classified according to their gender and their risk appetite. The result is given in the following table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e9cbf-2be8-434d-8944-edfe2f61d2dc",
   "metadata": {},
   "source": [
    "| **Gender/Risk Appetite** | Very Low | Low | Medium | High | Very High | Total |\n",
    "|:--------------------:|:--------:|:---:|:------:|:----:|:---------:|:-----:|\n",
    "|        **Female**        |    53    |  23 |   30   |  36  |     88    |  230  |\n",
    "|         **Male**         |    71    |  48 |   51   |  57  |    203    |  430  |\n",
    "|         **Total**        |    124   |  71 |   81   |  93  |    291    |  660  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d65429-303b-4302-b92b-5e8221b5a496",
   "metadata": {},
   "source": [
    "Test the hypothesis that the risk appetite of the customers in this company is independent of their gender. Use α = 0.01.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5fb172-bffb-407f-8c9c-80abb1561615",
   "metadata": {},
   "source": [
    "$H_{0}$: Gender and risk appetite are independent.   \n",
    "$H_{1}$: Gender and risk appetite are dependent. \n",
    "\n",
    "chi2 test should be used for this question. This test is known as the goodness-of-fit test. It implies that if the observed data are very close to the expected data. The assumption of this test every Ei ≥ 5 (in at least 80% of the cells) which is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0820ec81-e24d-41ab-aaeb-72a4b1a718cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected frequencies:\n",
      "  [[ 43.21  24.74  28.23  32.41 101.41]\n",
      " [ 80.79  46.26  52.77  60.59 189.59]]\n",
      "degrees of freedom: 4\n",
      "test stat :7.0942\n",
      "p value:0.1310\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "obs =np.array([[53, 23, 30, 36, 88],[71, 48, 51, 57, 203]])\n",
    "chi2, p, dof, ex = chi2_contingency(obs, correction=False)\n",
    "\n",
    "print(\"expected frequencies:\\n \", np.round(ex,2))\n",
    "print(\"degrees of freedom:\", dof)\n",
    "print(\"test stat :%.4f\" % chi2)\n",
    "print(\"p value:%.4f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41d2a38d-459f-4210-a065-ab1b756189f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical stat:13.2767\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "## calculate critical stat\n",
    "\n",
    "alpha = 0.01\n",
    "df = (5-1)*(2-1)\n",
    "critical_stat = chi2.ppf((1-alpha), df)\n",
    "print(\"critical stat:%.4f\" % critical_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863da29-daf9-4292-8b21-80e772743f41",
   "metadata": {},
   "source": [
    "Since p value is larger than α=0.01 ( or calculated statistic=7.14 is smaller than the critical statistic=13.28) >> Fail to Reject H0. At this significance level, it can be concluded that gender and risk appetite are independent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
